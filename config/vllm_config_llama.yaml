# config.yaml

model: "./storage/llama3.1-8b-awq"
host: "0.0.0.0"
port: 8002
max_model_len: 4096   # equivalent to --max-model-len 8k
gpu_memory_utilization: 0.8
quantization: awq
dtype: half
uvicorn_log_level: "info"